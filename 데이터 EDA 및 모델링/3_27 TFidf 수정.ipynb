{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3_21 모델학습 후 예측한 결과가 심통치않아 새로 전처리해보기로 하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터를 이용한 모델을 생성해서 문자열 값을 리턴 받아보자.\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Naver Sentiment Movie Corpus v1.0 다운로드\n",
    "train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
    "test_file = tf.keras.utils.get_file('test.txt',  'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일을 이진모드로 읽어온다. 디코드는 utf8로한다.\n",
    "train_text = open(train_file,'rb').read().decode(encoding='utf-8')\n",
    "test_text = open(test_file,'rb').read().decode(encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id\\tdocument\\tlabel\\n9976970\\t아 더빙.. 진짜 짜증나네요 목소리\\t0\\n3819312\\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\\t1\\n10265843'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a= train_text.split('\\n')[1:][0]\n",
    "\n",
    "a.split('\\t')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['아 더빙.. 진짜 짜증나네요 목소리',\n",
       " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
       " '너무재밓었다그래서보는것을추천한다']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X 값 추출 = 리뷰문장 == 피쳐\n",
    "x_train = [ row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t')>0]\n",
    "x_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150000, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y값 추출  == target\n",
    "y_train= np.array([ [int(row.split('\\t')[2])] for row in train_text.split('\\n')[1:] if row.count('\\t')>0])\n",
    "y_test= np.array([ [int(row.split('\\t')[2])] for row in test_text.split('\\n')[1:] if row.count('\\t')>0])\n",
    "print(y_train.shape) # (150000개의 평점 , 1개의 열)\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['아', '더빙', '..', '진짜', '짜증나네요', '목소리'],\n",
       " ['흠',\n",
       "  '...',\n",
       "  '포스터',\n",
       "  '보고',\n",
       "  '초딩',\n",
       "  '영화',\n",
       "  '줄',\n",
       "  '....',\n",
       "  '오버',\n",
       "  '연기',\n",
       "  '조차',\n",
       "  '가볍지',\n",
       "  '않구나'],\n",
       " ['너', '무재', '밓었', '다그', '래서', '보는것을', '추천', '한', '다'],\n",
       " ['교도소', '이야기', '구먼', '..', '솔직히', '재미', '는', '없다', '..', '평점', '조정'],\n",
       " ['사이',\n",
       "  '몬페',\n",
       "  '그',\n",
       "  '의',\n",
       "  '익살스런',\n",
       "  '연기',\n",
       "  '가',\n",
       "  '돋보였던',\n",
       "  '영화',\n",
       "  '!',\n",
       "  '스파이더맨',\n",
       "  '에서',\n",
       "  '늙어',\n",
       "  '보이기만',\n",
       "  '했던',\n",
       "  '커스틴',\n",
       "  '던스트',\n",
       "  '가',\n",
       "  '너무나도',\n",
       "  '이뻐',\n",
       "  '보였다']]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from konlpy.tag import Okt  #트위터에서 만든 한국어분석 메서드\n",
    "from konlpy.tag import Kkma  #서울대에서 만든거 morphs== 형태소 분석\n",
    "\n",
    "\n",
    "x_tokenized = [ ]\n",
    "for i in x_train[:100]:\n",
    "    x_tokenized.append( Okt().morphs( i ) ) \n",
    "    \n",
    "x_tokenized[:5]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ". ! ? ;;; 은 는 이 가 => 불용어 제거\n",
    "불용어 빈도수가 늘어남 = 중요도 판별하는 순위가 되기 때문에\n",
    "=> TF-IDF  TF= 빈도수  IDF = 역 빈도수 \n",
    "\n",
    "0 부정문들만 모여있는 문서\n",
    "1 긍정문들만 모여있는 문서\n",
    "\n",
    "=> TF-IDF 알고리즘은 두 문서에 겹치는 단어들 동시에 많이 쓰이는 단어들은 점수를 낮게\n",
    "=> 겹치지않는 단어들은 점수를 높게 매겨준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>원작의 긴장감을 제대로 살려내지못했다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>마이클베이 최근작을 볼때마다 느낀다. 블록버스터 액션장르라도 탄탄한 시나리오는 영화...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>0점은없나?1점은 너무 후하네</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>미달이는.. 연예계를 바라보는 태도를 고쳐야 한다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>파괴된 관객들.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>중견배우들이 만들어놓은 긴장감이 나름 긴장감있게 싸워보려했던 도술사들에 의해 헛웃음...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>508 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0  0\n",
       "0                                  아 더빙.. 진짜 짜증나네요 목소리  0\n",
       "2                                    너무재밓었다그래서보는것을추천한다  0\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정  0\n",
       "5        막 걸음마 뗀 3세부터 초등학교 1학년생인 8살용영화.ㅋㅋㅋ...별반개도 아까움.  0\n",
       "6                                원작의 긴장감을 제대로 살려내지못했다.  0\n",
       "..                                                 ... ..\n",
       "993  마이클베이 최근작을 볼때마다 느낀다. 블록버스터 액션장르라도 탄탄한 시나리오는 영화...  0\n",
       "994                                   0점은없나?1점은 너무 후하네  0\n",
       "995                       미달이는.. 연예계를 바라보는 태도를 고쳐야 한다.  0\n",
       "996                                           파괴된 관객들.  0\n",
       "998  중견배우들이 만들어놓은 긴장감이 나름 긴장감있게 싸워보려했던 도술사들에 의해 헛웃음...  0\n",
       "\n",
       "[508 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "x_train[:100] #1차원\n",
    "\n",
    "\n",
    "y_train[:100]  #2차원 \n",
    "\n",
    "x_df = pd.DataFrame(x_train[:1000])\n",
    "# print(x_df)\n",
    "\n",
    "y_df = pd.DataFrame(y_train[:1000])\n",
    "# print(y_df)\n",
    "\n",
    "# pd.DataFrame(x_df, y_df, columns=['x','y'], axis= 1)\n",
    "\n",
    "df = pd.concat([x_df, y_df], axis=1)\n",
    "\n",
    "# df\n",
    "# df.rename(columns={0, 0 : 'x','y'})\n",
    "# df_1= df[ (df.iloc[1:] ==0) ] \n",
    "\n",
    "\n",
    "bad = df[df.iloc[:,1]==0]\n",
    "good = df[df.iloc[:,1]==1]\n",
    "\n",
    "bad\n",
    "# TF-IDF 단어 중요도 점수를 매긴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>미달이는.. 연예계를 바라보는 태도를 고쳐야 한다.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>파괴된 관객들.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>알콜중독자들 덕에 평점이 낮은가?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>중견배우들이 만들어놓은 긴장감이 나름 긴장감있게 싸워보려했던 도술사들에 의해 헛웃음...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>남자 주인공 늑대 인간으로 변하고 끝나네유. 평점 보고 안 볼까 하다가 봤는디 재밌...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0                                  아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1                    흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2                                    너무재밓었다그래서보는것을추천한다      0\n",
       "3                        교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4    사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1\n",
       "..                                                 ...    ...\n",
       "995                       미달이는.. 연예계를 바라보는 태도를 고쳐야 한다.      0\n",
       "996                                           파괴된 관객들.      0\n",
       "997                                 알콜중독자들 덕에 평점이 낮은가?      1\n",
       "998  중견배우들이 만들어놓은 긴장감이 나름 긴장감있게 싸워보려했던 도술사들에 의해 헛웃음...      0\n",
       "999  남자 주인공 늑대 인간으로 변하고 끝나네유. 평점 보고 안 볼까 하다가 봤는디 재밌...      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df.rename(columns={0: 'A', '0': 'B'})\n",
    "\n",
    "df.columns.values[0] = 'text'\n",
    "df.columns.values[1] = 'label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:162\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\_libs\\index.pyx:197\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine._get_loc_duplicates\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uk246\\Desktop\\일억조 프로젝트\\데이터 EDA 및 모델링\\3_27 TFidf 수정.ipynb 셀 13\u001b[0m in \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X40sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:3772\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m \u001b[39m# GH#45316 Return view if key is not duplicated\u001b[39;00m\n\u001b[0;32m   3766\u001b[0m \u001b[39m# Only use drop_duplicates with duplicates for performance\u001b[39;00m\n\u001b[0;32m   3767\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_mi \u001b[39mand\u001b[39;00m (\n\u001b[0;32m   3768\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique\n\u001b[0;32m   3769\u001b[0m     \u001b[39mand\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   3770\u001b[0m     \u001b[39mor\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mdrop_duplicates(keep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3771\u001b[0m ):\n\u001b[1;32m-> 3772\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_item_cache(key)\n\u001b[0;32m   3774\u001b[0m \u001b[39melif\u001b[39;00m is_mi \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mand\u001b[39;00m key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns:\n\u001b[0;32m   3775\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4279\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m   4274\u001b[0m res \u001b[39m=\u001b[39m cache\u001b[39m.\u001b[39mget(item)\n\u001b[0;32m   4275\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4276\u001b[0m     \u001b[39m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[0;32m   4277\u001b[0m     \u001b[39m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[1;32m-> 4279\u001b[0m     loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(item)\n\u001b[0;32m   4280\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ixs(loc, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m   4282\u001b[0m     cache[item] \u001b[39m=\u001b[39m res\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[0;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'text'"
     ]
    }
   ],
   "source": [
    "df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "good.iloc[:,0]\n",
    "\n",
    "goodlist= np.array( [good.iloc[:,0]] )\n",
    "# print(goodlist)\n",
    "badlist= np.array( [ bad.iloc[:,0]])\n",
    "# df.iloc[:,0]\n",
    "\n",
    "gl=[ ]\n",
    "for i in goodlist[0]:\n",
    "    gl.append(i)\n",
    "bl= [ ]\n",
    "for i in badlist[0]:\n",
    "    bl.append(i)\n",
    "    \n",
    "texts= [gl,bl]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\uk246\\Desktop\\일억조 프로젝트\\데이터 EDA 및 모델링\\3_27 TFidf 수정.ipynb 셀 13\u001b[0m in \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkonlpy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtag\u001b[39;00m \u001b[39mimport\u001b[39;00m Okt\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m vectorizer \u001b[39m=\u001b[39m TfidfVectorizer( tokenizer\u001b[39m=\u001b[39m Okt()\u001b[39m.\u001b[39mmorphs ) \u001b[39m# 매개변수를 조정하여 다양한 옵션을 적용할 수 있습니다.\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m X \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mfit_transform(texts)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# y = df['label']\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# X=test111.iloc[:,0]\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# y=test111.iloc[:,1]\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/%EB%8D%B0%EC%9D%B4%ED%84%B0%20EDA%20%EB%B0%8F%20%EB%AA%A8%EB%8D%B8%EB%A7%81/3_27%20TFidf%20%EC%88%98%EC%A0%95.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# X\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2121\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2114\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2115\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2116\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2117\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2118\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2119\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2120\u001b[0m )\n\u001b[1;32m-> 2121\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2122\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2123\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2124\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1377\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1369\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1370\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1371\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1372\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1373\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1374\u001b[0m             )\n\u001b[0;32m   1375\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1377\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1379\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1380\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1264\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1263\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1264\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1265\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1266\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:111\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    110\u001b[0m     \u001b[39mif\u001b[39;00m preprocessor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 111\u001b[0m         doc \u001b[39m=\u001b[39m preprocessor(doc)\n\u001b[0;32m    112\u001b[0m     \u001b[39mif\u001b[39;00m tokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    113\u001b[0m         doc \u001b[39m=\u001b[39m tokenizer(doc)\n",
      "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:69\u001b[0m, in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[39mapply to a document.\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39m    preprocessed string\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mif\u001b[39;00m lower:\n\u001b[1;32m---> 69\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39;49mlower()\n\u001b[0;32m     70\u001b[0m \u001b[39mif\u001b[39;00m accent_function \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     doc \u001b[39m=\u001b[39m accent_function(doc)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "vectorizer = TfidfVectorizer( tokenizer= Okt().morphs ) # 매개변수를 조정하여 다양한 옵션을 적용할 수 있습니다.\n",
    "X = vectorizer.fit_transform(texts)\n",
    "# y = df['label']\n",
    "\n",
    "# X=test111.iloc[:,0]\n",
    "# y=test111.iloc[:,1]\n",
    "\n",
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딥러닝 모델\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "# from tensorflow.keras.\n",
    "\n",
    "#딥러닝기반 언어(텍스트정제 => 숫자로된 시계열데이터로 들어온다 )처리모델 \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#들어온 시퀀스데이터를 벡터로 변환한다.5000==단어사전크기, 600 차원은 클수록 좋다. 인풋랭스는 시퀀스데이터의 길이이다.\n",
    "model.add( Embedding( 3000, 200, input_length = 3468)) #입력층\n",
    "\n",
    "model.add( LSTM( units = 50) )   #은닉층,  units: 뉴런갯수 많을수록 좋다.\n",
    "\n",
    "#0부정,1긍정\n",
    "model.add( Dense( 2, activation='softmax' ))  #출력층\n",
    "#activation='softmax'이면 자동으로 loss='sparse_categorical_crossentropy'이다.\n",
    "\n",
    "\n",
    "# compile: ex) c언어 소스코드 => 컴터가 못알아들음 => 그럼면 알아들을수있게 컴파일해준다.\n",
    "#컴파일  , optimazer, loss ,metrics\n",
    "# sparse_categorical_crossentropy는 categorical_crossentropy와 동일하지만, 정수 형태의 레이블을 사용\n",
    "model.compile(optimizer='adam',  loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01199996, 0.00654543, 0.00436362, ..., 0.00109091, 0.        ,\n",
       "        0.00327272],\n",
       "       [0.05326131, 0.02441143, 0.00887688, ..., 0.00110961, 0.00155952,\n",
       "        0.00443844]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train=np.array([\n",
    "    [0],\n",
    "    [1]\n",
    "])\n",
    "\n",
    "X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.6985 - acc: 0.0000e+00 - val_loss: 0.7525 - val_acc: 0.0000e+00\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.6371 - acc: 1.0000 - val_loss: 0.8222 - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5789 - acc: 1.0000 - val_loss: 0.8994 - val_acc: 0.0000e+00\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.5222 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.0000e+00\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.4653 - acc: 1.0000 - val_loss: 1.0960 - val_acc: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25bea38d030>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit( X_tfidf.toarray(), y_train, epochs=5, batch_size = 500 , validation_split = 0.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#테스트 문자열 생성\n",
    "# test = ['프로젝트 개망했다.'] \n",
    "test = ['상당히 볼만했다. 재미있었다.']\n",
    "\n",
    "test = vectorizer.transform(test)\n",
    "test.toarray()\n",
    "\n",
    "test = idf.transform( test )\n",
    "test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.6658059 , 0.33419412]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(test.toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
