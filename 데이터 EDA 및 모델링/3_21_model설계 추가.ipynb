{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 벡터를 이용한 모델을 생성해서 문자열 값을 리턴 받아보자.\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Kuiyh5YqxFfu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Naver Sentiment Movie Corpus v1.0 다운로드\n",
        "train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "test_file = tf.keras.utils.get_file('test.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')"
      ],
      "metadata": {
        "id": "GGD740JTxJzE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#파일을 이진모드로 읽어온다. 디코드는 utf8로한다.\n",
        "text_train = open(train_file,'rb').read().decode(encoding='utf-8')\n",
        "text_test = open(test_file,'rb').read().decode(encoding='utf-8')"
      ],
      "metadata": {
        "id": "3J4s9dJmxOBR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_g03jnQxOb8",
        "outputId": "169364aa-70cf-4c11-9552-0f0e23cdb768"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train y값 label을 먼저 뽑는다. \n",
        "a=text_train[:500].split('\\n')[1:]\n",
        "#줄마다 나눠서 a에 넣는다.\n",
        "print(a[:5])\n",
        "print(a[3].count('\\t'))\n",
        "# a[5]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMCZi4F5xO5t",
        "outputId": "82511811-0296-441c-d050-9712f62c358f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['9976970\\t아 더빙.. 진짜 짜증나네요 목소리\\t0', '3819312\\t흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나\\t1', '10265843\\t너무재밓었다그래서보는것을추천한다\\t0', '9045019\\t교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정\\t0', '6483659\\t사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 던스트가 너무나도 이뻐보였다\\t1']\n",
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# '9976970\\t아 더빙.. 진짜 짜증나네요 목소리\\t0'\n",
        "# '9976970', '아 더빙.. 진짜 짜증나네요 목소리', '0'\n",
        "a[0].split('\\t')[2]  # 감상평의 라벨 0= 부정,  1= 긍정"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fmaWd3iOxO1y",
        "outputId": "f8320a08-1999-49b1-dcd2-7c07a51ef71a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for row in text_train.split('\\n')[1:]: \n",
        "#     print(row) #여기 한줄 뽑아서 \n",
        "#     print(row.split('\\t')[2]) #\\t 로 나눠서 2번째 원소인 라벨을 뽑는다\n",
        "#     print( int(row.split('\\t')[2]) ) # int() 해서 정수형으로 바꿔준다."
      ],
      "metadata": {
        "id": "JE6KBO02xOxD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 정제 \n",
        "\n",
        "print(text_test[:200])\n",
        "\n",
        "#각 줄을 \\n으로 분리하겠다.\n",
        "#헤더를 제외하겠다. \n",
        "\n",
        "#한줄마다 \\t로 분할해서 문장과 점수로 나눈다\n",
        "#감상평은 \\t로 구분되어있음\n",
        "# [1:]으로 헤더제거\n",
        "\n",
        "#감상평의 평점만 뽑아서 정수화 행렬로 만들어줬다.\n",
        "y_train= np.array([ [int(row.split('\\t')[2])] for row in text_train.split('\\n')[1:] if row.count('\\t')>0])\n",
        "y_test= np.array([ [int(row.split('\\t')[2])] for row in text_test.split('\\n')[1:] if row.count('\\t')>0])\n",
        "print(y_train.shape) # (150000개의 평점 , 1개의 열)\n"
      ],
      "metadata": {
        "id": "_Sjyp8_6xXxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75310d7f-6460-494f-87f3-4e5a550c3e62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id\tdocument\tlabel\n",
            "6270596\t굳 ㅋ\t1\n",
            "9274899\tGDNTOPCLASSINTHECLUB\t0\n",
            "8544678\t뭐야 이 평점들은.... 나쁘진 않지만 10점 짜리는 더더욱 아니잖아\t0\n",
            "6825595\t지루하지는 않은데 완전 막장임... 돈주고 보기에는....\t0\n",
            "6723715\t3D만 아니었어도 별 다섯 개 줬을텐데.. 왜 3D로 나와서 제 심\n",
            "(150000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_train.split('\\n')  #한줄씩 분리하고\n",
        "text_train.split('\\n')[1:]  #헤더 처리\n",
        "#row.count('\\t')>0   평점이 존재하면\n",
        "# row.split('\\t')[1]  감상평만 추출"
      ],
      "metadata": {
        "id": "T44rS7b7xYzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X 값 추출 = 리뷰문장\n",
        "x_train = [ row.split('\\t')[1] for row in text_train.split('\\n')[1:] if row .count('\\t')>0  ]\n",
        "x_train[:3]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-K9J4ipxYpc",
        "outputId": "f6d8e017-b336-4420-c498-70364292dd64"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아 더빙.. 진짜 짜증나네요 목소리',\n",
              " '흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나',\n",
              " '너무재밓었다그래서보는것을추천한다']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install konlpy"
      ],
      "metadata": {
        "id": "Wwy3T5pA02lu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#kkma로도 한번 해보기\n",
        "from konlpy.tag import Kkma\n",
        "\n",
        "# x_train 를 넣어본다.\n",
        "# Kkma().sentences( x_train[0] )\n",
        "\n",
        "#띄어쓰기기준으로 나눠서 토큰화\n",
        "x_train[0].split(' ')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4JNBRlSlvOV",
        "outputId": "97b0c9f5-630c-40ec-fab0-47e8cd5c9482"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['아', '더빙..', '진짜', '짜증나네요', '목소리']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#위에서 추출한 문장을 토큰화해볼것이다. => OKT 방법을 사용할것이다.\n",
        "from konlpy.tag import Okt\n",
        "#konlpy 패키지에있는 tag 모듈에 Okt 메서드를 불러온다.\n",
        "\n",
        "x_train_tokenized = []\n",
        "for i in x_train[:20000]: #너무오래걸려서 리뷰 2만개만\n",
        "    x_train_tokenized.append( Okt().morphs( i ) ) \n",
        "\n",
        "#시간이 오래걸리네 #GPU로 5분정도\n",
        "x_train_tokenized\n"
      ],
      "metadata": {
        "id": "JUY_Iu9-xYXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰화된 학습 데이터\n",
        "# x_train_tokenized[:100]\n",
        "# 나눠진 토큰들을 임베딩할것이다. \n",
        "len(x_train_tokenized)\n",
        "\n",
        "total_len = 0\n",
        "for i in x_train_tokenized:\n",
        "    total_len += len(i)\n",
        "print(total_len)  # 토큰 2,156,163 개  => 은, 는, 이, 가 이게 많이 나오면 중요 키워드인가? \n",
        "# 그렇지않다. => 그럼 제거한다\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGay4ODr7q5-",
        "outputId": "adea2828-588d-49f7-e8c4-52371e142006"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "289293\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "만약 의문문 대해서 커스텀을하고싶으면 \n"
      ],
      "metadata": {
        "id": "PRx484OO9PR_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Okt().morphs( '오늘 뭐먹었어?' )\n",
        "# Okt().morphs( '오늘 뭐했어?' ) #의문문에 대한 구분이 불가능 해보인다. "
      ],
      "metadata": {
        "id": "wz6iDFKv9YQm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words= 5000 ) #빈도가 높은것 순서대로 2만개만 다시 토큰화한다.\n",
        "\n",
        "#빈도수 기준으로 사전을 만든다.  단어사전 =단어순서대로 숫자를 부여한다(인덱싱)\n",
        "tokenizer.fit_on_texts( x_train_tokenized )\n",
        " \n",
        "\n",
        "# 인덱싱된 데이터들을 시계열데이터로 변환한다. == 수치화 == 정수 인코딩이라한다.  \n",
        "sequences = tokenizer.texts_to_sequences( x_train_tokenized )\n",
        "\n",
        "#이렇게 숫자로 바뀌면 이제 컴퓨터가 처리할수있는 데이터가 된다.\n",
        "sequences\n"
      ],
      "metadata": {
        "id": "LLbhS_nO-QkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "id": "Ci3k5bCxxky1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 패딩 == 공간을 준다.\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#가장 긴 문장을 기준으로 다른문장들도 길이를 맞춰준다.  늘어난 공간은 0 으로한다.\n",
        "X_train = pad_sequences(sequences,padding='post')  #학습데이터 완성\n",
        "# y_train\n",
        "\n",
        "# [1] => 세개 공간을 만들고 싶다. = pre앞에[0 0 1], post뒤에[1 0 0]"
      ],
      "metadata": {
        "id": "S0Y-arq8C8UE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[0]) #문장 하나의 시퀀스데이터\n",
        "print(X_train[0].shape)\n",
        "# (150000, 93) 15만개 리뷰, 가장긴 문장의 토큰개수 == 93 == 패딩된 값"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-GuQcyu0OrS",
        "outputId": "9d0706de-a85e-424e-f6cd-c1cbb329af73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 62 537   5  23 804   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0]\n",
            "(66,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "149MEFhc5fFP",
        "outputId": "376a5d02-c5ac-43e8-952c-db817d50ef4c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  62,  537,    5, ...,    0,    0,    0],\n",
              "       [ 822,    9,  391, ...,    0,    0,    0],\n",
              "       [ 371, 2243, 4778, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [ 290,  157,   43, ...,    0,    0,    0],\n",
              "       [  36,    6,   68, ...,    0,    0,    0],\n",
              "       [ 469,  919,  194, ...,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 딥러닝 모델\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "# from tensorflow.keras.\n",
        "\n",
        "#딥러닝기반 언어(텍스트정제 => 숫자로된 시계열데이터로 들어온다 )처리모델 \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#들어온 시퀀스데이터를 벡터로 변환한다.5000==단어사전크기, 600 차원은 클수록 좋다. 인풋랭스는 시퀀스데이터의 길이이다.\n",
        "model.add( Embedding( 5000, 1000, input_length = 66)) #입력층\n",
        "\n",
        "model.add( LSTM( units = 1000) )   #은닉층,  units: 뉴런갯수 많을수록 좋다.\n",
        "\n",
        "#0부정,1긍정\n",
        "model.add( Dense( 2, activation='softmax' ))  #출력층\n",
        "#activation='softmax'이면 자동으로 loss='sparse_categorical_crossentropy'이다.\n",
        "\n",
        "\n",
        "# compile: ex) c언어 소스코드 => 컴터가 못알아들음 => 그럼면 알아들을수있게 컴파일해준다.\n",
        "#컴파일  , optimazer, loss ,metrics\n",
        "# sparse_categorical_crossentropy는 categorical_crossentropy와 동일하지만, 정수 형태의 레이블을 사용\n",
        "model.compile(optimizer='adam',  loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n"
      ],
      "metadata": {
        "id": "1EoPdLxaEZ5z"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ickLgOmTHQoB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "# params == 파라미터 == 매개변수 == 가중치w랑 편향b의 개수 "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQ5-_1Nx7cZN",
        "outputId": "928dcf69-3e78-44ba-b3ec-a7c3cc13e2f6"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 66, 1000)          5000000   \n",
            "                                                                 \n",
            " lstm_4 (LSTM)               (None, 1000)              8004000   \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 2002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,006,002\n",
            "Trainable params: 13,006,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#모델을 학습시킨다.=> 새로운 데이터가오면 판단을 할수있다.\n",
        "model.fit( X_train, y_train, epochs=5, batch_size = 500 , validation_split = 0.2)\n",
        "#X =>   y\n",
        "#리뷰글 => 점수\n",
        "#피쳐  => 타겟\n",
        "#독립변수 => 종속변수\n",
        "#학습데이터 => 라벨링\n",
        "\n",
        "#모델링\n",
        "#모델에서 여러가지 바꿔봐도 성능이 개선되지않는다. => 전처리 과정을 바꿔봐야한다."
      ],
      "metadata": {
        "id": "6qVKf7wq7h54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 해보기\n",
        "a='영화 완전 노잼입니다.'  # 0이 나오면된다.\n",
        "\n",
        "b='대박 개꿀잼임ㄹㅇ'    # 1이 나오면된다.\n",
        "\n",
        "c='나쁘지도 않고 좋지도 않았다.'  #수빈님 예측=> 부정  이런거는 틀릴 수 밖에 없다. => 왜냐면 가르친적이 없다.\n",
        "# => 라벨 2를 추가해서 학습을 시킨다.\n",
        "\n"
      ],
      "metadata": {
        "id": "nTtYMwEBEuuh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}