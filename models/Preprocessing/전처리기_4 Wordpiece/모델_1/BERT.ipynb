{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# 사전 훈련된 BERT 모델 및 토크나이저 불러오기\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertModel.from_pretrained(model_name)\n",
    "\n",
    "# 입력 텍스트\n",
    "input_text = \"This is a simple BERT model example.\"\n",
    "\n",
    "# 텍스트 토큰화 및 텐서 변환\n",
    "input_tokens = tokenizer.encode(input_text, return_tensors='tf')\n",
    "\n",
    "# BERT 모델을 사용하여 텍스트 표현 추출\n",
    "outputs = model(input_tokens)\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "\n",
    "print(last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 사전 훈련된 BERT 모델 및 토크나이저 불러오기\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = TFBertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# 모델 컴파일\n",
    "optimizer = Adam(learning_rate=2e-5)\n",
    "model.compile(optimizer=optimizer, loss=model.compute_loss, metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
