{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5iox9kcqpD1"
      },
      "source": [
        "살짝 튜닝해본 모델에다가 카톡대화내역 불러오기 => 긍정부정 판다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glBvON29q6q7",
        "outputId": "808af61f-df45-4bfd-e53b-ab32fd5d3410"
      },
      "outputs": [],
      "source": [
        "# !pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FlJcCm9HtWrN"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "#1. Naver Sentiment Movie Corpus v1.0 다운로드\n",
        "train_file = tf.keras.utils.get_file('train.txt', 'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt')\n",
        "# test_file = tf.keras.utils.get_file( 'test.txt',  'https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt')\n",
        "\n",
        "#파일을 이진모드로 읽어온다. 디코드는 utf8로한다.\n",
        "train_text = open(train_file,'rb').read().decode(encoding='utf-8')\n",
        "# test_text = open(test_file,'rb').read().decode(encoding='utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DUl7FhWgqpD6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_train = pd.DataFrame({\n",
        "    'feature':[ row.split('\\t')[1] for row in train_text.split('\\n')[1:] if row.count('\\t')>0 ],\n",
        "    'target': [ int(row.split('\\t')[2]) for row in train_text.split('\\n')[1:] if row.count('\\t')>0]\n",
        "})\n",
        "\n",
        "#데이터 크기 지정\n",
        "df_train = df_train[::6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25000"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#문장 추출\n",
        "texts= [ ]\n",
        "for i in df_train['feature']:\n",
        "    texts.append(i)\n",
        "len(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "#문자열이 아닌게 있는지 확인\n",
        "for i in texts:\n",
        "    if type(i)!=str:\n",
        "        print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train 데이터 입력값(X)을 정제(Cleaning)\n",
        "import re\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "def clean_korean_text(text):\n",
        "    # 특수 문자 및 숫자 제거\n",
        "    text = re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣ\\s]', '', text)\n",
        "    # 반복되는 자음, 모음 제거 (e.g., 'ㅋㅋㅋ' -> 'ㅋ')\n",
        "    text = repeat_normalize(text, num_repeats=1)\n",
        "    # 띄어쓰기 정규화 (연속된 공백 문자를 하나의 공백 문자로 변환)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "clean_texts=[]\n",
        "for i in texts:\n",
        "    clean_texts.append(clean_korean_text(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['아 더빙 진짜 짜증나네요 목소리',\n",
              " '원작의 긴장감을 제대로 살려내지못했다',\n",
              " '울면서 손들고 횡단보도 건널때 뛰쳐나올뻔 이범수 연기 드럽게못해',\n",
              " '이건 정말 깨알 캐스팅과 질퍽하지않은 산뜻한 내용구성이 잘 버무러진 깨알일드',\n",
              " '주제는 좋은데 중반부터 지루하다']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(clean_texts)\n",
        "clean_texts[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sb3u5TZqqpD7",
        "outputId": "bc835d99-5d1e-4fe3-e2fb-00b681fb8624"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "#tfidf하면서 토큰화는 okt.morphs로 한다.\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from konlpy.tag import Okt\n",
        "\n",
        "vectorizer=TfidfVectorizer( tokenizer= Okt().morphs)\n",
        "X = vectorizer.fit_transform(clean_texts)\n",
        "y = df_train.iloc[:,1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUU3nDwiFMxz",
        "outputId": "975a9dab-bb12-4ac6-db51-3a357ed28ae2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(25000, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#불균형데이터확인\n",
        "df_train[df_train.iloc[:,1]==0]  #18678 \n",
        "df_train[df_train.iloc[:,1]==1]  #18822\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WXsMQ5HmuoR1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X_train_dense = np.expand_dims( X.toarray(), axis=-1 )\n",
        "# X_train_dense.shape\n",
        "# X.shape[1]\n",
        "# X.toarray().shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Ge7NOgY8uoKe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
            "  return t[start:end]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "350/350 [==============================] - 25s 62ms/step - loss: 0.6268 - accuracy: 0.6834 - val_loss: 0.5741 - val_accuracy: 0.7781\n",
            "Epoch 2/20\n",
            "350/350 [==============================] - 18s 51ms/step - loss: 0.3839 - accuracy: 0.8328 - val_loss: 0.4116 - val_accuracy: 0.8077\n",
            "Epoch 3/20\n",
            "350/350 [==============================] - 16s 44ms/step - loss: 0.2566 - accuracy: 0.8975 - val_loss: 0.4764 - val_accuracy: 0.7919\n",
            "Epoch 4/20\n",
            "350/350 [==============================] - 14s 41ms/step - loss: 0.1981 - accuracy: 0.9245 - val_loss: 0.5036 - val_accuracy: 0.7939\n",
            "Epoch 5/20\n",
            "350/350 [==============================] - 15s 44ms/step - loss: 0.1679 - accuracy: 0.9386 - val_loss: 0.5426 - val_accuracy: 0.7953\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1e1cbe6f3d0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#DNN\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization , Input, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "model = Sequential([\n",
        "    # input_layer,\n",
        "    Input(shape=(X_train_dense.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.6),\n",
        "    Dense(32, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.6),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# 모델 컴파일 및 학습\n",
        "optimizer= Adam(learning_rate=0.002)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 콜백 정의\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
        "\n",
        "# model.fit(X.toarray(), y, epochs = 10, batch_size = 500, validation_split=0.2)  #0.8417\n",
        "model.fit(\n",
        "    X.toarray(), y, \n",
        "    epochs = 20, batch_size = 50, \n",
        "    validation_split=0.3,\n",
        "    callbacks=[early_stopping]\n",
        "    ) \n",
        "\n",
        "#Okt()토크나이저를 넣지 않았을 때\n",
        "# loss: 0.1659 - accuracy: 0.9387 - val_loss: 0.5841 - val_accuracy: 0.7403\n",
        "#okt() 토크나이저를 썼을 때\n",
        "# loss: 0.1598 - accuracy: 0.9409 - val_loss: 0.5469 - val_accuracy: 0.8003\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0EClS3xeynli"
      },
      "outputs": [],
      "source": [
        "# model.save('3_31_DNN 튜닝모델.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Bl6oAcdct68I"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 266ms/step\n",
            "[[0.6815217 ]\n",
            " [0.01179763]\n",
            " [0.6967079 ]]\n",
            "예측 결과: [[1]\n",
            " [0]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "test_texts = ['이거 정말 잼따. ', '아니 무슨 이딴게 다있냐;;','ㅋ']\n",
        "\n",
        "#문자열이 아닌게 있는지 확인\n",
        "for i in test_texts:\n",
        "    if type(i)!=str:\n",
        "        print(i)\n",
        "        \n",
        "# train 데이터 입력값(X)을 정제(Cleaning)\n",
        "import re\n",
        "from soynlp.normalizer import repeat_normalize\n",
        "\n",
        "def clean_korean_text(text):\n",
        "    # 특수 문자 및 숫자 제거\n",
        "    text = re.sub(r'[^가-힣ㄱ-ㅎㅏ-ㅣ\\s]', '', text)\n",
        "\n",
        "    # 반복되는 자음, 모음 제거 (e.g., 'ㅋㅋㅋ' -> 'ㅋ')\n",
        "    text = repeat_normalize(text, num_repeats=1)\n",
        "\n",
        "    # 띄어쓰기 정규화 (연속된 공백 문자를 하나의 공백 문자로 변환)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "clean_test_texts=[]\n",
        "for i in test_texts:\n",
        "    clean_test_texts.append(clean_korean_text(i))\n",
        "\n",
        "# 학습된 TF-IDF 벡터라이저로 테스트 데이터 변환\n",
        "X_test_sample = vectorizer.transform(clean_test_texts)\n",
        "X_test_sample_dense = X_test_sample.toarray()\n",
        "\n",
        "# 모델을 사용하여 예측 수행\n",
        "predictions = model.predict(X_test_sample_dense)\n",
        "print(predictions)\n",
        "\n",
        "# 예측 결과 출력 (긍정: 1, 부정: 0)\n",
        "print(\"예측 결과:\", np.round( predictions ).astype(int))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "닉네임기준으로 \n",
        "카톡대화내용을 기준으로 테스트 문장을 여러개 불러와서 예측 후 그 값의 비율을 계산 출력해준다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['김찬란', '오후 10:01', '사진'],\n",
              " ['김찬란', '오후 9:38', 'https://youtube.com/watch?v=o1G7DWFFHso&feature=share'],\n",
              " ['김찬란', '오후 10:42', '사진'],\n",
              " ['김찬란', '오후 10:42', '사기치고다니는 한장규'],\n",
              " ['김하영', '오후 10:45', '이야'],\n",
              " ['김하영', '오후 10:46', '게임에서도 치네'],\n",
              " ['김찬란', '오후 10:46', '진짜 니말이 맞다 진짜 친구면 친구한테 민폐되기 싫어서 돈빌려달란 소리도 안한다'],\n",
              " ['김하영', '오전 12:25', '이모티콘'],\n",
              " ['김하영', '오전 12:35', '회식끝나고 집가는중'],\n",
              " ['김찬란', '오전 12:35', '음음 초밥집 회식은 어디서 하냐'],\n",
              " ['김하영', '오전 12:35', '우리 실장형네 직이 고기집해서 글로갔다'],\n",
              " ['김하영', '오전 12:36', '회식하면 맨날 돼지고기만 먹는다'],\n",
              " ['김찬란', '오전 12:36', 'ㅋㅋㅋㅋㅋㅋ케'],\n",
              " ['김하영', '오전 12:36', '이모티콘'],\n",
              " ['김찬란', '오전 12:36', '아 내수용 회식'],\n",
              " ['김찬란', '오전 12:36', '사진'],\n",
              " ['김하영', '오전 12:36', 'ㅋㅋㅋㅋ 그런거 아니고 애들이 여기가 맛있다고 여기서먹음'],\n",
              " ['김찬란', '오전 12:37', '고기 얘시하니까'],\n",
              " ['김찬란', '오전 12:37', '나도 고기가 먹고 싶군'],\n",
              " ['김하영', '오전 12:37', 'ㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오전 12:37', '낼 사먹어야겠다'],\n",
              " ['김하영', '오전 12:37', '와라 엉아가 소고기 사줄께'],\n",
              " ['김찬란', '오전 12:37', '내가 사야지 씹새야 입벌려'],\n",
              " ['김찬란', '오전 12:37', '고기 들어간'],\n",
              " ['김찬란', '오전 12:38', '너는 내가 사주고 싶으니까 '],\n",
              " ['김찬란', '오전 12:38', '취직해서 올라가면 함보자'],\n",
              " ['김하영', '오전 12:39', '어야~~ 언제 취직하냐 김짤랑'],\n",
              " ['김찬란', '오전 12:39', '올 여름'],\n",
              " ['김하영', '오전 12:39', 'ㅋㅋㅋㅋ 뭔데??'],\n",
              " ['김하영', '오전 12:40', '공무원 김짤랑??'],\n",
              " ['김찬란', '오전 12:40', '머신러닝 엔지니어'],\n",
              " ['김하영', '오전 12:40', '그건또 뭔 하이테크냐??'],\n",
              " ['김하영', '오전 12:40', '샵검색: #머신러닝'],\n",
              " ['김찬란', '오전 12:41', '인공지능 로밧'],\n",
              " ['김찬란', '오전 12:41', '인간시대의 끝이 도래한다'],\n",
              " ['김하영', '오전 12:41', '저거 보들보들하냐??'],\n",
              " ['김하영', '오전 12:41', '안무냐??'],\n",
              " ['김찬란', '오전 12:41', '배만지면 통통햐'],\n",
              " ['김찬란', '오전 12:41', '격렬하게 저항하는데'],\n",
              " ['김찬란', '오전 12:41', '그것도 귀여움'],\n",
              " ['김하영', '오전 12:42', 'ㅋㅋㅋㅋ 안물면 상관없다'],\n",
              " ['김찬란', '오전 12:42', '계속만지면 자포자기하더라'],\n",
              " ['김찬란', '오전 12:42', '포기하고 배를 내어쥼'],\n",
              " ['김하영', '오전 12:42', '주인이랑 성격이 똑같네'],\n",
              " ['김찬란', '오전 12:42', '?'],\n",
              " ['김찬란', '오전 12:43', '츕다 '],\n",
              " ['김찬란', '오전 12:43', '언능 들어가쇼'],\n",
              " ['김찬란', '오전 12:43', '길바닥에서 얼어뒤짐'],\n",
              " ['김하영', '오전 12:43', '이미 집왔다'],\n",
              " ['김찬란', '오전 12:43', '맞나'],\n",
              " ['김하영', '오전 12:43', '돈 편하게 많이 벌고싶다~~'],\n",
              " ['김찬란', '오전 12:44', '넌 잘할둣'],\n",
              " ['김찬란', '오전 12:44', '열심히 일하면 잘될겨'],\n",
              " ['김하영', '오전 12:44', '지금 번아웃 온거같다'],\n",
              " ['김찬란', '오전 12:44', '등꼴빼먹는 사기뀬만 안만나면'],\n",
              " ['김하영', '오전 12:44', 'ㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오전 12:44', '번아웃 올정도로 열심히하나'],\n",
              " ['김찬란', '오전 12:44', '얼마나 벌길래'],\n",
              " ['김하영', '오전 12:45', '일단 세전 300에'],\n",
              " ['김하영', '오전 12:45', '투자금+a'],\n",
              " ['김찬란', '오전 12:45', '하루에 3시간씩자몀서 투잡 쓰리잡하는 사람도봄 '],\n",
              " ['김하영', '오전 12:45', '투자금 0~300'],\n",
              " ['김하영', '오전 12:45', '매달'],\n",
              " ['김찬란', '오전 12:45', '나 세전 31만원'],\n",
              " ['김하영', '오전 12:45', 'ㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오전 12:45', '코인 10'],\n",
              " ['김하영', '오전 12:45', '코인뭔데'],\n",
              " ['김찬란', '오전 12:46', '리플'],\n",
              " ['김하영', '오전 12:46', 'ㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오전 12:46', 'ㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 12:46', 'ㅈㄴ 강제독립되가지고'],\n",
              " ['김하영', '오전 12:46', '힘들다 숨만쉬어도 달에 170빠짐'],\n",
              " ['김찬란', '오전 12:46', '와 '],\n",
              " ['김찬란', '오전 12:46', '너무 많이 빠지는데'],\n",
              " ['김찬란', '오전 12:46', '세금이랑 방ㅅ랑 합쳐도'],\n",
              " ['김하영', '오전 12:47', '연봉으로 치면 5천 좀 넘는거같은데'],\n",
              " ['김하영', '오전 12:47', '모이는게없음'],\n",
              " ['김찬란', '오전 12:47', 'ㅇㅇ 마이 버네'],\n",
              " ['김찬란', '오전 12:47', '글게'],\n",
              " ['김하영', '오전 12:47', '여자친구 집에서 키우고'],\n",
              " ['김하영', '오전 12:47', '외식을 줄여야하는데'],\n",
              " ['김찬란', '오전 12:47', '여친이 있네'],\n",
              " ['김찬란', '오전 12:47', '방금 프사 봄'],\n",
              " ['김하영', '오전 12:47', '같이산다'],\n",
              " ['김하영', '오전 12:47', 'ㅋㅋㅋㅋ '],\n",
              " ['김하영', '오전 12:48', '5살 연하임'],\n",
              " ['김찬란', '오전 12:48', '결혼람?'],\n",
              " ['김찬란', '오전 12:48', '완전 도둑시키네'],\n",
              " ['김하영', '오전 12:48', '이제 스물셋인ㄷ!?'],\n",
              " ['김찬란', '오전 12:48', '라고할뻔'],\n",
              " ['김찬란', '오전 12:48', '도랏나 완전 얼란데'],\n",
              " ['김하영', '오전 12:48', '2년전에 많이들었다 이거'],\n",
              " ['김찬란', '오전 12:49', '완전 도랏네 암튼 츅하한다'],\n",
              " ['김하영', '오전 12:49', '이모티콘'],\n",
              " ['김찬란', '오전 12:49', '와 나는 23살 이란 대화만 해도'],\n",
              " ['김찬란', '오전 12:49', '세대차이 느껴지던대ㅔ'],\n",
              " ['김하영', '오전 12:49', 'ㅈㄴ 웃기네 ㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 12:49', '맞음'],\n",
              " ['김찬란', '오전 12:49', '드라마,좋아하는노래 등등 세대가 달라'],\n",
              " ['김찬란', '오전 12:50', '저번에 슴셋함테 이세돌아냐고 물어보ㅓㅆ다가'],\n",
              " ['김하영', '오전 12:50', '얘네 친척언니들이 무슨 그렇게 나이 차이나는 남자 만나냐그럼'],\n",
              " ['김찬란', '오전 12:50', 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 12:50', '나랑 동갑이거든'],\n",
              " ['김하영', '오전 12:50', 'ㅋㅋㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오전 12:50', 'ㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 12:51', '아니 슴셋이랑 슴여덜'],\n",
              " ['김찬란', '오전 12:51', '음 생각보다 안나는것같기도'],\n",
              " ['김찬란', '오전 12:51', '나 고삼때 25 남자 만나던 애도'],\n",
              " ['김찬란', '오전 12:51', '있었는데 그게 ㅈㄴ짜 개십새낒'],\n",
              " ['김찬란', '오전 12:51', '라고할뻔'],\n",
              " ['김하영', '오전 12:52', 'ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 12:52', '여자애가'],\n",
              " ['김하영', '오전 12:52', '이쁨??'],\n",
              " ['김찬란', '오전 12:52', '고삼이 25남자 만나더라'],\n",
              " ['김찬란', '오전 12:52', '이뻣음'],\n",
              " ['김찬란', '오전 12:52', '내기준'],\n",
              " ['김하영', '오전 12:52', '개웃기네'],\n",
              " ['김하영', '오전 12:52', '이게 참 거시기함'],\n",
              " ['김찬란', '오전 12:53', '내기준 이쁜사람'],\n",
              " ['김찬란', '오전 12:53', '샵검색: #이수현'],\n",
              " ['김찬란', '오전 12:53', '마지노선'],\n",
              " ['김하영', '오전 12:54', 'ㅈㄴ 낮네'],\n",
              " ['김찬란', '오전 12:54', 'ㅇㅇ 난 성격 많이봄'],\n",
              " ['김하영', '오전 12:54', '짤랑 좋은 여자 만나겠네'],\n",
              " ['김찬란', '오전 12:54', '근데 여자들이 날 안좋아하더라'],\n",
              " ['김하영', '오전 12:54', '솔직히 나는 연애고 결혼이고 내가 좋아하는거보다'],\n",
              " ['김하영', '오전 12:54', '아 시발'],\n",
              " ['김찬란', '오전 12:55', 'ㅇㅇ'],\n",
              " ['김찬란', '오전 12:55', '니가 좋아하는것보다 '],\n",
              " ['김찬란', '오전 12:55', '좋아해주는 사람이 좋음?'],\n",
              " ['김하영', '오전 12:55', '여자가 남자를 더 좋아해 주는게'],\n",
              " ['김하영', '오전 12:55', '훨씬 좋다고 생각함'],\n",
              " ['김찬란', '오전 12:55', '그런맛이 있지'],\n",
              " ['김하영', '오전 12:55', '좀 이기적일수도 있는데'],\n",
              " ['김찬란', '오전 12:56', '그게 이기적이면 대부분의 여자가 이기적인거지 ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 12:56', '그럴슈도있지'],\n",
              " ['김하영', '오전 12:56', '남자가 여자한테 매달리게되면 답이 없음'],\n",
              " ['김하영', '오전 12:57', '퍼주고 끝나는거만 봐서'],\n",
              " ['김찬란', '오전 12:57', '그런여자들은 좋은 사람 놓치는겨'],\n",
              " ['김찬란', '오전 12:57', '그렇게 해주는 사람이 어딧냐'],\n",
              " ['김하영', '오전 12:57', '이모티콘'],\n",
              " ['김찬란', '오전 12:57', '시골은 그런사람 귀함'],\n",
              " ['김찬란', '오전 12:57', '너도나도 시집가려할듯'],\n",
              " ['김하영', '오전 12:58', '그놈의 시골'],\n",
              " ['김하영', '오전 12:58', 'ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 12:58', 'ㄹㅇ임'],\n",
              " ['김하영', '오전 12:58', '남자없냐??'],\n",
              " ['김찬란', '오전 12:58', '술만 안마셔도 바로 시집가는 사람도 있음'],\n",
              " ['김찬란', '오전 12:58', '멀쫑한 남자가 별로없지'],\n",
              " ['김찬란', '오전 12:59', '나도 집착 당해보고 싶다'],\n",
              " ['김찬란', '오전 12:59', '상전이 된기뷴일둣'],\n",
              " ['김하영', '오전 1:00', '언젠가는 생길거다'],\n",
              " ['김하영', '오전 1:00', '일단'],\n",
              " ['김하영', '오전 1:00', '살부터 빼 새끼야'],\n",
              " ['김찬란', '오전 1:00', '나 74밖에 안나가 지굼'],\n",
              " ['김찬란', '오전 1:00', '태퓽 불면 날아갈듯'],\n",
              " ['김찬란', '오전 1:00', '아니 아이폰 미니 샀는데'],\n",
              " ['김찬란', '오전 1:01', '오타 미친다 자찬 개짝음'],\n",
              " ['김하영', '오전 1:01', 'ㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:01', '플립이나 쓰지'],\n",
              " ['김하영', '오전 1:01', '왜 아이폰 쓰냐'],\n",
              " ['김하영', '오전 1:01', '플립 좋은데'],\n",
              " ['김찬란', '오전 1:01', '사진'],\n",
              " ['김찬란', '오전 1:01', '뇌섹녀다 '],\n",
              " ['김하영',\n",
              "  '오전 1:01',\n",
              "  'https://m.blog.naver.com/PostView.naver?blogId=wax96&logNo=222870410153&proxyReferer='],\n",
              " ['김하영', '오전 1:02', '이거 여자친구가 너 닮았데'],\n",
              " ['김찬란', '오전 1:02', '나무늘보??'],\n",
              " ['김하영', '오전 1:02', '맞데'],\n",
              " ['김하영', '오전 1:02', 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:02', '아 존나 웃기네'],\n",
              " ['김찬란', '오전 1:02', 'ㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:02', '아니 나 만나는 사람마다 뭐 닮았데'],\n",
              " ['김하영', '오전 1:03', '유니크 하긴해'],\n",
              " ['김하영', '오전 1:03', '우리 짤랑이'],\n",
              " ['김찬란', '오전 1:03', 'ㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:03', '오ㅑ 내개ㅏ 느그 짤랑이냐'],\n",
              " ['김찬란', '오전 1:03', '우리 친형만이 부르는 별명이다'],\n",
              " ['김하영', '오전 1:03', '그럼 누구네 짤랑이냐 너가'],\n",
              " ['김하영', '오전 1:03', 'ㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:04', '자빠져 자시요'],\n",
              " ['김찬란', '오전 1:04', '여친이랑 잘놀고'],\n",
              " ['김찬란', '오전 1:04', '나 낼 경찰서 가야뎀'],\n",
              " ['김하영', '오전 1:04', '사진'],\n",
              " ['김찬란', '오전 1:05', '맨두?'],\n",
              " ['김하영', '오전 1:05', '어야 난 여자친구 빵굽는거 보다가 겜좀 하고 자야겠당'],\n",
              " ['김하영', '오전 1:05', '만두아니고'],\n",
              " ['김하영', '오전 1:05', '소금빵이라고'],\n",
              " ['김하영', '오전 1:05', '승질내는중'],\n",
              " ['김하영', '오전 1:05', '잘자라 짤랑'],\n",
              " ['김찬란', '오전 1:05', '앜ㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:06', '뀰잠 잘듯'],\n",
              " ['김찬란', '오전 1:06', '두근두근 경찰서 모험'],\n",
              " ['김하영', '오전 1:06', 'ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:06', '경찰 아찌들 '],\n",
              " ['김하영', '오전 1:06', '짤랑이 경찰서도 가고 많이 컷네'],\n",
              " ['김찬란', '오전 1:06', '무섭다'],\n",
              " ['김하영', '오전 1:06', '니가 범죄자만 아니면 친젏마'],\n",
              " ['김찬란', '오전 1:06', '긍게'],\n",
              " ['김찬란', '오전 1:06', '나 범죄자일지도'],\n",
              " ['김하영', '오전 1:06', '뭐했는데 ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:06', '돈 내놓으라고 협박하긴 랬음'],\n",
              " ['김하영', '오전 1:06', '개웃기네 진짜'],\n",
              " ['김찬란', '오전 1:06', '갚으라고'],\n",
              " ['김하영', '오전 1:06', '신고할꺼라고?'],\n",
              " ['김하영', '오전 1:07', '이게 진짜 거지같은게'],\n",
              " ['김찬란', '오전 1:07', '사진'],\n",
              " ['김하영', '오전 1:07', '빌려줄때는 애원하는데'],\n",
              " ['김하영', '오전 1:07', '받을때는 내가 애원해야한다'],\n",
              " ['김찬란', '오전 1:07', '개욕받았눈데'],\n",
              " ['김하영', '오전 1:07', 'ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:07', '존나 화났네'],\n",
              " ['김찬란', '오전 1:07', '애원안하지왜해'],\n",
              " ['김하영', '오전 1:07', '진짜 개귀엽네'],\n",
              " ['김하영', '오전 1:07', '우리짤랑이'],\n",
              " ['김찬란', '오전 1:07', '애교 부이면 돌돌려받나'],\n",
              " ['김하영', '오전 1:08', 'ㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:08', '주겠냐?'],\n",
              " ['김하영', '오전 1:08', 'ㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:08', 'ㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:08', '진짜 빌려줄때는'],\n",
              " ['김하영', '오전 1:08', '얘한테는 안받아도 상관없어'],\n",
              " ['김하영', '오전 1:08', '라는 놈들한테만'],\n",
              " ['김하영', '오전 1:08', '빌려줘라'],\n",
              " ['김하영', '오전 1:08', '몇만원이든 몇십이든 몇백이든'],\n",
              " ['김찬란', '오전 1:08', '나 '],\n",
              " ['김하영', '오전 1:08', '아무리 친해도 받기 힘듦'],\n",
              " ['김찬란', '오전 1:08', '알면서 당한듯'],\n",
              " ['김하영', '오전 1:09', 'ㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오전 1:09', '알고도 당하는 매직'],\n",
              " ['김하영', '오전 1:09', '마음이 약해서 그럼'],\n",
              " ['김하영', '오전 1:09', '나도 진짜'],\n",
              " ['김하영', '오전 1:09', '많이 당해서'],\n",
              " ['김찬란', '오전 1:09', '친구 아버지 돕는다는 생각으로'],\n",
              " ['김찬란', '오전 1:09', '시부랄'],\n",
              " ['김하영', '오전 1:09', '맞지'],\n",
              " ['김찬란', '오전 1:09', '좋는생각으로 빌려쥰건데'],\n",
              " ['김찬란', '오전 1:09', '후 죽여버리고 싶다'],\n",
              " ['김찬란', '오전 1:10', '후련하려나'],\n",
              " ['김하영', '오전 1:10', 'ㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:10', '절대'],\n",
              " ['김하영', '오전 1:10', '안 후련하다 절대로'],\n",
              " ['김하영', '오전 1:10', '깜빵넣어도'],\n",
              " ['김찬란', '오전 1:10', '아니야'],\n",
              " ['김찬란', '오전 1:10', '존나 후련할듯'],\n",
              " ['김하영', '오전 1:10', 'ㅋㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김하영', '오전 1:10', '진정해라'],\n",
              " ['김하영', '오전 1:10', '김짤랑'],\n",
              " ['김찬란', '오전 1:10', '아 감빵은 감당 안된다'],\n",
              " ['김찬란', '오전 1:10', '암살햐야지'],\n",
              " ['김찬란', '오전 1:10', '내가 쥭인건 몰르게'],\n",
              " ['김찬란', '오전 1:10', '후..'],\n",
              " ['김하영', '오전 1:11', '도경이가'],\n",
              " ['김하영', '오전 1:11', '젤불쌍하다'],\n",
              " ['김찬란', '오전 1:11', 'ㅋㅋㅋㅋㅋㅋ '],\n",
              " ['김하영', '오전 1:11', '진짜 착한애를 갖다가'],\n",
              " ['김하영', '오전 1:11', '씹새끼'],\n",
              " ['김하영', '오전 1:11', '짤랑이가 돈이 없어서 망정이지'],\n",
              " ['김찬란', '오전 1:11', '진짜 사람 착하고 열심히사는사람린데'],\n",
              " ['김하영', '오전 1:11', '진짜'],\n",
              " ['김찬란', '오전 1:11', '도경이'],\n",
              " ['김하영', '오전 1:11', '누구한테는 연봉인데'],\n",
              " ['김찬란', '오전 1:12', '1 소나타'],\n",
              " ['김찬란', '오전 1:12', '내 드림카임'],\n",
              " ['김찬란', '오전 1:12', '멋뎌'],\n",
              " ['김하영', '오전 1:13', '나는 재규어'],\n",
              " ['김하영', '오전 1:13', '였는데 이제 우라칸'],\n",
              " ['김찬란', '오전 1:17', '남자의 차'],\n",
              " ['김찬란', '오전 1:18', '샵검색: #팰리세이드'],\n",
              " ['김찬란', '오전 1:18', '잘빠졌다\\\\'],\n",
              " ['김찬란', '오전 1:18', '샵검색: #재규어'],\n",
              " ['김찬란', '오전 1:18', '삼촌 한분이 이거 애지중지하던데 비싼거였구나'],\n",
              " ['김찬란', '오전 1:19', '맨날 손세차하더라 만날떄마다'],\n",
              " ['김하영', '오전 1:26', 'ㅋㅋㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오후 9:08', '파일: 고소장 초안.hwp'],\n",
              " ['김찬란', '오후 9:08', '자새끼좀 감방에 넣어쥬세요 '],\n",
              " ['김하영', '오후 9:16', 'ㅋㅋㅋㅋ'],\n",
              " ['김하영', '오후 9:16', '아직 초안이넹'],\n",
              " ['김찬란', '오후 9:57', '아이고 주민번호 그대로 올려버렸네'],\n",
              " ['김하영', '오후 9:57', 'ㅋㅋㅋㅋ '],\n",
              " ['김하영', '오후 9:57', '필요없다~~'],\n",
              " ['김찬란', '오후 9:57', '하긴 쓸데없긴함'],\n",
              " ['김하영', '오후 9:57', '개웃기네'],\n",
              " ['김찬란', '오후 9:59', '기분이 너무안좋으니까 맜있는거라도 먹어야겠다'],\n",
              " ['김하영', '오후 9:59', '난 여친와야 먹어서'],\n",
              " ['김하영', '오후 9:59', '기다리는중'],\n",
              " ['김찬란', '오후 9:59', '엄청 늦ㄱ오네'],\n",
              " ['김찬란', '오후 10:00', '일하고 오는겨'],\n",
              " ['김하영', '오후 10:00', '나 10시~10시 여자친구 2잡'],\n",
              " ['김찬란', '오후 10:00', '와 다들 얄심히 사는구나'],\n",
              " ['김하영', '오후 10:00', '10시반~4시 6시~10시반'],\n",
              " ['김하영', '오후 10:01', '열심히 살아도 모자르다 인생이'],\n",
              " ['김찬란', '오후 10:03', '진짜 얄심히구나 난 아직 취업을 안해서 남들 어떻게 사는지도 잘모르네'],\n",
              " ['김하영', '오후 10:03', '다들 분수에 맞게 사는거지'],\n",
              " ['김찬란', '오후 10:04', '같이 수업듣는 사람 한명이 엄청 성슉하고 어른 같아서 당연히 나보다 훨씬 어른 인줄알았는대'],\n",
              " ['김찬란', '오후 10:04', '또래였름'],\n",
              " ['김하영', '오후 10:04', '그 이상 잘살고싶으면 남들보다 열심히 해야하거'],\n",
              " ['김하영', '오후 10:04', '한두살 많냐??'],\n",
              " ['김찬란', '오후 10:04', '한살 많았음'],\n",
              " ['김하영', '오후 10:05', '그냥 극 I라서 말수없고 내성적인거 아니고??'],\n",
              " ['김찬란', '오후 10:05', 'ㅋㅋㅋㅋㅋ 그런가'],\n",
              " ['김찬란', '오후 10:05', '긍데 알고 보니까 광고업체 사장이더라 '],\n",
              " ['김하영', '오후 10:05', '힘들게 살'],\n",
              " ['김하영', '오후 10:05', '뭐야시발'],\n",
              " ['김찬란', '오후 10:05', '대단함'],\n",
              " ['김하영', '오후 10:05', '금수저인가...?'],\n",
              " ['김하영', '오후 10:05', '자영업 인가??'],\n",
              " ['김찬란', '오후 10:05', '그건 모르는데 '],\n",
              " ['김찬란', '오후 10:06', '수업 듣다가 중도 포기하고 가더라'],\n",
              " ['김하영', '오후 10:06', '뭐 업체도 업체 나름 이지만'],\n",
              " ['김하영', '오후 10:06', '열심히 사는쪽 사람같네'],\n",
              " ['김찬란', '오후 10:06', '큰건 아닌거 닽고'],\n",
              " ['김하영', '오후 10:07', '운이란건 준비된 놈이 가져가는거다 짤랑'],\n",
              " ['김하영', '오후 10:07', '진화해라'],\n",
              " ['김하영', '오후 10:07', '아구몬 마냥'],\n",
              " ['김찬란', '오후 10:07', 'ㅋㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오후 10:07', '슬램덩크 보러 가야지'],\n",
              " ['김하영', '오후 10:07', 'ㅋㅋㅋㅋㅋㅋ '],\n",
              " ['김찬란', '오후 10:07', '아니'],\n",
              " ['김하영', '오후 10:07', '이모티콘'],\n",
              " ['김찬란', '오후 10:07', '넷플 더글로리 보삼'],\n",
              " ['김하영', '오후 10:08', '봄'],\n",
              " ['김찬란', '오후 10:08', '엤날 생각도 나고'],\n",
              " ['김찬란', '오후 10:08', '암튼 그래'],\n",
              " ['김하영', '오후 10:08', '짤랑이 내 고데기 온도좀 체크해줄래?'],\n",
              " ['김찬란', '오후 10:08', '삼겹살 구워주게?'],\n",
              " ['김하영', '오후 10:08', '그거 구워줘?'],\n",
              " ['김찬란', '오후 10:08', '대패삽겹이면 되지 않을까'],\n",
              " ['김찬란', '오후 10:09', '무슨 대화냐'],\n",
              " ['김하영', '오후 10:09', '더글로리 심한거 같진않던데'],\n",
              " ['김하영', '오후 10:09', '더한거 많이 봐서 그런가 어릴때'],\n",
              " ['김찬란', '오후 10:09', '뭘봤기래'],\n",
              " ['김하영', '오후 10:09', '전라도라 그런가'],\n",
              " ['김하영', '오후 10:09', '중3 형들이 수금시키고'],\n",
              " ['김하영', '오후 10:10', '왕따시키고'],\n",
              " ['김찬란', '오후 10:10', '흠'],\n",
              " ['김하영', '오후 10:10', '빵셔틀 맞짱 패싸움'],\n",
              " ['김하영', '오후 10:10', '대가리끼리 일기토'],\n",
              " ['김하영', '오후 10:10', '별에별거'],\n",
              " ['김찬란', '오후 10:10', '나도 시골인데 일진들의 폭력은 항상 있었음'],\n",
              " ['김하영', '오후 10:10', '시골이라 심한듯'],\n",
              " ['김하영', '오후 10:10', '여기 애들이랑 얘기해보면'],\n",
              " ['김하영', '오후 10:11', '안믿음'],\n",
              " ['김찬란', '오후 10:11', '안믿기긴람'],\n",
              " ['김하영', '오후 10:11', '여기 욕하고 주먹질하면 천박하다 그러면서 말싸움하는동네임'],\n",
              " ['김하영', '오후 10:11', '강남이라 그런가'],\n",
              " ['김찬란', '오후 10:12', 'ㅋㅋㅋㅋㅋ 뒷담하고 정치하고 그런거'],\n",
              " ['김하영', '오후 10:12', '아리랑치기는 술취한사람 지갑훔치는거 아니냐??'],\n",
              " ['김찬란', '오후 10:12', '아마 그런의미도 있울걸'],\n",
              " ['김하영', '오후 10:12', '샵검색: #아리랑치기'],\n",
              " ['김하영', '오후 10:12', '와'],\n",
              " ['김하영', '오후 10:13', '국어사전에 있는말이네'],\n",
              " ['김하영', '오후 10:13', '이딴게 사전?'],\n",
              " ['김찬란', '오후 10:13', 'ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오후 10:14', '아왠지 자꾸 고기 생각이 나더라니'],\n",
              " ['김찬란', '오후 10:14', '먹을려고해ㅛ던 고기를 안먹어 줬네'],\n",
              " ['김하영', '오후 10:14', 'ㅋㅋㅋㅋ '],\n",
              " ['김하영', '오후 10:14', '냉장고에 주무시는중이냐??'],\n",
              " ['김찬란', '오후 10:14', '장도 안봐왔음'],\n",
              " ['김찬란', '오후 10:14', '깜빡함'],\n",
              " ['김하영', '오후 10:18', '움직이기 귀찮다'],\n",
              " ['김하영', '오후 10:18', '움직여라 몸'],\n",
              " ['김찬란', '오후 10:19', '누가 칼들고 협박한다고 생각하면'],\n",
              " ['김찬란', '오후 10:20', '빨리빨리 움직여짐'],\n",
              " ['김찬란', '오후 10:20', '개뀰팁'],\n",
              " ['김하영', '오후 10:20', '안무서우면?'],\n",
              " ['김찬란', '오후 10:20', '그롬 진짜 뒤지는거지'],\n",
              " ['김찬란', '오후 10:20', '칼맞고 '],\n",
              " ['김하영', '오후 10:20', 'ㅋ!ㅋㅋㅋㅋ'],\n",
              " ['김찬란', '오후 10:20', '너뮤 끔직했다'],\n",
              " ['김하영', '오전 10:28', '이모티콘']]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 카톡대화 불러와서 정제,(정규화코드)하는 함수\n",
        "import re\n",
        "\n",
        "def get_from_txt(txt):\n",
        "    data= open(txt,\"r\", encoding='utf-8').read().split('\\n')\n",
        "    sentences=[]\n",
        "    for line in data:\n",
        "        pattern = r'\\[(.*?)\\]\\s+\\[(.*?)\\]\\s+(.+)'\n",
        "        match = re.match(pattern, line)\n",
        "        if match:\n",
        "            name = match.group(1)  # 첫 번째 대괄호 안의 단어 추출\n",
        "            time = match.group(2)  # 두 번째 대괄호 안의 단어 추출\n",
        "            content = match.group(3)  # 대괄호 뒤의 내용 추출\n",
        "            # print(name, time, content)\n",
        "            temp=[name,time,content]\n",
        "            sentences.append(temp)    \n",
        "    return sentences\n",
        "\n",
        "#함수확인\n",
        "get_from_txt('sample.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#닉네임 입력단 \n",
        "target_name = str(input())\n",
        "print(target_name)  #김하영 입력"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Found array with 0 sample(s) (shape=(0, 35800)) while a minimum of 1 is required by TfidfTransformer.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\uk246\\Desktop\\일억조 프로젝트\\models\\모델1 감성(긍정부정)분류\\model_1_DNN_카톡대화입력.ipynb 셀 18\u001b[0m in \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/models/%EB%AA%A8%EB%8D%B81%20%EA%B0%90%EC%84%B1%28%EA%B8%8D%EC%A0%95%EB%B6%80%EC%A0%95%29%EB%B6%84%EB%A5%98/model_1_DNN_%EC%B9%B4%ED%86%A1%EB%8C%80%ED%99%94%EC%9E%85%EB%A0%A5.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m clean2_received_texts\u001b[39m=\u001b[39m [clean_korean_text(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m clean1_received_texts]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/models/%EB%AA%A8%EB%8D%B81%20%EA%B0%90%EC%84%B1%28%EA%B8%8D%EC%A0%95%EB%B6%80%EC%A0%95%29%EB%B6%84%EB%A5%98/model_1_DNN_%EC%B9%B4%ED%86%A1%EB%8C%80%ED%99%94%EC%9E%85%EB%A0%A5.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39m# # 학습된 TF-IDF 벡터라이저로 테스트 데이터 변환\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/models/%EB%AA%A8%EB%8D%B81%20%EA%B0%90%EC%84%B1%28%EA%B8%8D%EC%A0%95%EB%B6%80%EC%A0%95%29%EB%B6%84%EB%A5%98/model_1_DNN_%EC%B9%B4%ED%86%A1%EB%8C%80%ED%99%94%EC%9E%85%EB%A0%A5.ipynb#X23sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m X_received_texts \u001b[39m=\u001b[39m vectorizer\u001b[39m.\u001b[39;49mtransform(clean2_received_texts)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/models/%EB%AA%A8%EB%8D%B81%20%EA%B0%90%EC%84%B1%28%EA%B8%8D%EC%A0%95%EB%B6%80%EC%A0%95%29%EB%B6%84%EB%A5%98/model_1_DNN_%EC%B9%B4%ED%86%A1%EB%8C%80%ED%99%94%EC%9E%85%EB%A0%A5.ipynb#X23sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m X_received_texts_dense \u001b[39m=\u001b[39m X_received_texts\u001b[39m.\u001b[39mtoarray()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/uk246/Desktop/%EC%9D%BC%EC%96%B5%EC%A1%B0%20%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8/models/%EB%AA%A8%EB%8D%B81%20%EA%B0%90%EC%84%B1%28%EA%B8%8D%EC%A0%95%EB%B6%80%EC%A0%95%29%EB%B6%84%EB%A5%98/model_1_DNN_%EC%B9%B4%ED%86%A1%EB%8C%80%ED%99%94%EC%9E%85%EB%A0%A5.ipynb#X23sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m \u001b[39m# # 모델을 사용하여 예측 수행\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:2146\u001b[0m, in \u001b[0;36mTfidfVectorizer.transform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   2143\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m, msg\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe TF-IDF vectorizer is not fitted\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   2145\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mtransform(raw_documents)\n\u001b[1;32m-> 2146\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tfidf\u001b[39m.\u001b[39;49mtransform(X, copy\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
            "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:1699\u001b[0m, in \u001b[0;36mTfidfTransformer.transform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1682\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, X, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   1683\u001b[0m     \u001b[39m\"\"\"Transform a count matrix to a tf or tf-idf representation.\u001b[39;00m\n\u001b[0;32m   1684\u001b[0m \n\u001b[0;32m   1685\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m \u001b[39m        Tf-idf-weighted document-term matrix.\u001b[39;00m\n\u001b[0;32m   1698\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1699\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[0;32m   1700\u001b[0m         X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES, copy\u001b[39m=\u001b[39;49mcopy, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m   1701\u001b[0m     )\n\u001b[0;32m   1702\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m sp\u001b[39m.\u001b[39missparse(X):\n\u001b[0;32m   1703\u001b[0m         X \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39mcsr_matrix(X, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mfloat64)\n",
            "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:535\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    534\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 535\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    536\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    537\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
            "File \u001b[1;32mc:\\Users\\uk246\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    927\u001b[0m     n_samples \u001b[39m=\u001b[39m _num_samples(array)\n\u001b[0;32m    928\u001b[0m     \u001b[39mif\u001b[39;00m n_samples \u001b[39m<\u001b[39m ensure_min_samples:\n\u001b[1;32m--> 929\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    930\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFound array with \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m sample(s) (shape=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) while a\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    931\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m minimum of \u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m is required\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    932\u001b[0m             \u001b[39m%\u001b[39m (n_samples, array\u001b[39m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[0;32m    933\u001b[0m         )\n\u001b[0;32m    935\u001b[0m \u001b[39mif\u001b[39;00m ensure_min_features \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    936\u001b[0m     n_features \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
            "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 35800)) while a minimum of 1 is required by TfidfTransformer."
          ]
        }
      ],
      "source": [
        "# 저장된 모델 불러오기\n",
        "# from tensorflow.keras.models import load_models\n",
        "# model= load_models('3_31_DNN 튜닝모델.h5')\n",
        "\n",
        "\n",
        "#입력된 이름의 '대화내역만' 담기\n",
        "received_texts= []\n",
        "for i in get_from_txt('sample.txt'): \n",
        "    if i[0] == target_name:\n",
        "        received_texts.append( i[2] )\n",
        "        \n",
        "# 이모티콘, 사진, 샵검색 제거 \n",
        "clean1_received_texts = []\n",
        "for i in received_texts:\n",
        "    if '샵검색:' not in i: \n",
        "        if \"이모티콘\" not in i:\n",
        "            if '샵검색:' not in i:\n",
        "                clean1_received_texts.append(str(i))\n",
        "\n",
        "#=========== 이쯤에서 답장시간 계산기 구현   =======================\n",
        "          \n",
        "          \n",
        "#텍스트 정제  \n",
        "clean2_received_texts= [clean_korean_text(i) for i in clean1_received_texts]\n",
        "\n",
        "# # 학습된 TF-IDF 벡터라이저로 테스트 데이터 변환\n",
        "X_received_texts = vectorizer.transform(clean2_received_texts)\n",
        "X_received_texts_dense = X_received_texts.toarray()\n",
        "\n",
        "\n",
        "# # 모델을 사용하여 예측 수행\n",
        "predictions = np.round(model.predict(X_received_texts_dense))\n",
        "#예측 결과 출력 (긍정: 1, 부정: 0)\n",
        "print(predictions.squeeze().tolist()) #차원을 축소하고 리스트객체로 변환\n",
        "\n",
        "cnt0=0;cnt1=0\n",
        "for i in predictions.squeeze().tolist():\n",
        "    if int(i)==0:\n",
        "        cnt0+=1\n",
        "    else:\n",
        "        cnt1+=1\n",
        "\n",
        "#부정과 긍정문의 갯수\n",
        "print('부정문과 긍정문의 갯수:',cnt0,cnt1)\n",
        "\n",
        "#긍정과 부정의 비율( 긍정문의 수 / 부정문의 수)\n",
        "print('긍정과 부정의 비율: ',cnt1/cnt0)\n",
        "#숫자가 1이상이고 높을수록 긍정적이다.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
